# -*- coding: utf-8 -*-
"""M5 Ejercicio4 ErickSandoval.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-pOOfSP5lmJwF7TFDT9EcZASSHVFLSNC

# **Setup**
"""

import pandas as pd
import numpy as np

import matplotlib.pyplot as plt
from matplotlib import style
import seaborn as sns

# Configuración matplotlib
plt.rcParams['image.cmap'] = "bwr"
#plt.rcParams['figure.dpi'] = "100"
plt.rcParams['savefig.bbox'] = "tight"
style.use('ggplot') or plt.style.use('ggplot')

# Configuración warnings
import warnings
warnings.filterwarnings('ignore')

"""# **Data**"""

data = pd.read_csv('https://raw.githubusercontent.com/Rwyld/Data-Science-Models/main/Modelos/Regresion%20Logistica/RRHH%20CSV.csv')
display(data.head(15))

"""# **Analisis Exploratorios**"""

data.info()

data.isnull().sum()

infoData = data
infoData = infoData.drop('Estado.Civil', axis = 1)
infoData.describe()

"""Se observan algunas posibles incongruensias en la variable de Salario """

fig, axe = plt.subplots(2, 2, figsize=(12,8))

axe[0, 0].hist(data['Edad'], bins = 50)
axe[0, 1].hist(data['Salario'], bins = 50)
axe[1, 0].hist(data['Ratio.Pago'], bins = 50)
axe[1, 1].hist(data['Dias.trabajados'], bins = 50)

axe[0, 0].set_xlabel('Edad')
axe[0, 0].set_ylabel('Personas')
axe[0, 0].set_title('Distribucion de Edades', fontsize = 10, fontweight = "bold")
axe[0, 0].tick_params(labelsize = 7)

axe[0, 1].set_xlabel('Salario')
axe[0, 1].set_ylabel('USD')
axe[0, 1].set_title('Distribucion de Salarios', fontsize = 10, fontweight = "bold")
axe[0, 1].tick_params(labelsize = 7)

axe[1, 0].set_xlabel('Pago por Hora')
axe[1, 0].set_ylabel('Personas')
axe[1, 0].set_title('Distribucion de Horas por Personas', fontsize = 10, fontweight = "bold")
axe[1, 0].tick_params(labelsize = 7)

axe[1, 1].set_xlabel('Dias totales trabajados')
axe[1, 1].set_ylabel('Personas')
axe[1, 1].set_title('Distribucion de Dias por Personas', fontsize = 10, fontweight = "bold")
axe[1, 1].tick_params(labelsize = 7)

fig.tight_layout()
plt.subplots_adjust(top=0.9)
plt.show()

"""Con estos graficos realizados, podemos observar que existen algunos salarios que superan los 8000 USD, lo que es sospechoso, por lo tanto hay que identificar primero si estan correctos o no."""

dataSalarios = data['Salario'].sort_values(ascending = False)

display(dataSalarios.head(5))
print('')
display(dataSalarios.tail(5))

"""Como el sueldo minimo de la empresa esta entre los 3000+ USD, los sueldos sobre 8000 USD deberian ser omitidos, ya que son posibles candidatos de ser datos incongruentes. Ademas revisando los datos de la variable Edad, se observan algunos datos incongruentes dentro de la tabla.

Por lo tanto, los datos incongruentes seran omitidos, al igual que las variables Estado Civil, Posicion, Desempeño y Departamento

# **Construyendo nuevo DataFrame con las variables continuas**
"""

newData = data.loc[:, ['Estado', 'Edad',	'Ratio.Pago',  'Salario',	'Dias.trabajados',	'Ausencias']]

#Eliminando Edades incongruentes
newData = newData.drop(index = newData[newData['Edad']%1 != 0].index)

#Eliminando Salarios muy altos
newData = newData.drop(index = newData[newData['Salario'] > 8000].index)

newData.head(5)

"""# **Modelo Regresion Logistica**"""

X = newData.iloc[:,newData.columns != 'Estado'] 
y = newData.Estado

from sklearn.model_selection import train_test_split


X_train, X_test, y_train, y_test = train_test_split(
                                        X,
                                        y,
                                        train_size   = 0.75,
                                        random_state = 2023,
                                        shuffle      = True
                                    )

import statsmodels.api as sm

X_train = sm.add_constant(X_train, prepend=True)
modelo = sm.Logit(endog=y_train, exog=X_train,)
modelo = modelo.fit()
print(modelo.summary())

"""# **Metricas**"""

X_test = sm.add_constant(X_test, prepend=True)
predicciones = modelo.predict(exog = X_test)
clasificacion = np.where(predicciones<0.5, 0, 1)

from sklearn import metrics

cnf_matrix = metrics.confusion_matrix(y_test, clasificacion)
cnf_matrix

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

class_names=[0,1] # name  of classes
fig, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)
# create heatmap
sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap="YlGnBu" ,fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Confusion matrix', y=1.1)
plt.ylabel('Actual label')
plt.xlabel('Predicted label');

from sklearn.metrics import precision_score
from sklearn.metrics import accuracy_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score



#Calculo la sensibilidad del modelo
sensibilidad = recall_score(y_test, clasificacion)
print('Sensibilidad del modelo:')
print(sensibilidad)

#Calculo el Puntaje F1 del modelo
puntajef1 = f1_score(y_test, clasificacion)
print('Puntaje F1 del modelo:')
print(puntajef1)

#Calculo la exactitud del modelo
exactitud = accuracy_score(y_test, clasificacion)
print('Exactitud del modelo:')
print(exactitud)

#Calculo la precisión del modelo
precision = precision_score(
            y_true = y_test, 
            y_pred = clasificacion)
print('Precisión del modelo:')
print(precision)

fpr, tpr, _ = metrics.roc_curve(y_test,  clasificacion)
auc = metrics.roc_auc_score(y_test, clasificacion)
plt.plot(fpr,tpr,label="data 1, auc="+str(auc))
plt.legend(loc=4)
plt.show()

from sklearn.metrics import roc_auc_score

roc_auc = roc_auc_score(y_test, clasificacion)
print('Curva ROC - AUC del modelo:')
print(roc_auc)

"""# **Interpretacion**

Con lo observado en el modelo, podemos concluir que las variables Salario y Ausencias no son significativos y que no se puede afirmar que tienen relacion con el Estado del empleado. Sin embargo, las variables Edad, Ratio y Dias, son significativos.

De acuerdo a las metricas obtenidas del modelo, este modelo posee una Exactitud del 77% y una precision del 70%. En cuanto al valor de AUC es de 0.77, el cual es cercano a 1 y que tiene un buen desempeño para distinguir los casos positivos y negativos.

#C**onstruyendo nuevo DataFrame con las variables categoricas**
"""

sns.countplot(x='Sexo', hue='Estado', data=data)

sns.countplot(x='Estado.Civil', hue='Estado', data=data)

sns.countplot(x='Departamento', hue='Estado', data=data)
plt.xticks(rotation=45, ha='right')
plt.show()

plt.figure(figsize=(15, 4))
sns.countplot(x='Posicion', hue='Estado', data=data)
plt.xticks(rotation=45, ha='right')

plt.show()

sns.countplot(x='Desempeño', hue='Estado', data=data)
plt.xticks(rotation=45, ha='right')
plt.show()

"""# **Modelo Regresion Logistica para variables Categoricas**"""

dataCateg = pd.get_dummies(data, columns=['Sexo', 'Estado.Civil', 'Departamento', 'Desempeño'])
A = dataCateg.drop(['Estado','Posicion'], axis=1)
b = dataCateg['Estado']

A = A.astype(int)

#Train Test split 75/25
A_train, A_test, b_train, b_test = train_test_split(
                                        A,
                                        b,
                                        train_size   = 0.75,
                                        random_state = 2023,
                                        shuffle      = True
                                    )

modeloC = sm.Logit(b_train, A_train)
modeloC = modeloC.fit()
print(modeloC.summary())

"""Segun los datos obtenidos con el modelo para observar si las categorias tienen relacion con el estado del empleado, se puede concluir que no son significativas para determinar el estado, puesto que poseen un p value de 1. """