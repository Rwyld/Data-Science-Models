# -*- coding: utf-8 -*-
"""M5 Ejercicio7 ErickSandoval.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QfRN7EnjQvxifsN20NRuNKOa38pgq04N

# **Setup**
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn import preprocessing
from sklearn.pipeline import Pipeline
from sklearn.naive_bayes import MultinomialNB
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import classification_report

data70 = 'https://raw.githubusercontent.com/Rwyld/Data-Science-Models/main/Modelos/Naive%20Bayes/train.csv'
data30 = 'https://raw.githubusercontent.com/Rwyld/Data-Science-Models/main/Modelos/Naive%20Bayes/test.csv'

trainData = pd.read_csv(data70)
testData = pd.read_csv(data30)

trainData.head(3)

testData.head()

"""# **Analisis Exploratorio**"""

print("Train data shape:", trainData.shape)
print("Test data shape:", testData.shape)

registrosTrain = pd.crosstab(index=trainData['Activity'], columns='count')
registrosTest = pd.crosstab(index=testData['Activity'], columns='count')

fig, ax = plt.subplots(2, 1, figsize=(10,8))

sns.barplot(data=registrosTrain, x=registrosTrain.index, y=registrosTrain['count'], ax=ax[0])
sns.barplot(data=registrosTest, x=registrosTest.index, y=registrosTest['count'], ax=ax[1])

ax[0].tick_params(axis='x', labelsize = 8)
ax[0].set_title('Train Data')
ax[1].tick_params(axis='x', labelsize = 8)
ax[1].set_title('Test Data')

plt.tight_layout()
plt.show()

"""Existe un pequeño desbalance en los datos que corresponden a Walking Downstairs y Walking Uptairs, observandose posiblemente mas datos en

# **Definiendo y Estandarizando variables**
"""

X_train = trainData.drop(['Activity', 'subject'], axis=1)
X_test = testData.drop(['Activity', 'subject'], axis=1)
y_train = trainData['Activity']
y_test = testData['Activity']

X_train_stand = StandardScaler().fit_transform(X_train)
X_test_stand = StandardScaler().fit_transform(X_test)

encoder = preprocessing.LabelEncoder().fit(y_train)

y_train_new = encoder.transform(y_train)
y_test_new = encoder.transform(y_test)

scaler = MinMaxScaler()
X_train_scaled = scaler.fit_transform(X_train_stand)
X_test_scaled = scaler.transform(X_test_stand)

"""# **Ajustando el Modelo Naive Bayes**"""

pipeline =  Pipeline([
    ('MnB', MultinomialNB(fit_prior=False)),
])

parameters = {'MnB__alpha':[0.1, 0.5, 1.0, 2.0]}

nb_grid = GridSearchCV(pipeline,parameters, cv=10)
nb_grid.fit(X_train_scaled, y_train_new)

print('Mejor parámetros:', nb_grid.best_params_)

bestAlpha = nb_grid.best_params_['MnB__alpha']
nb = MultinomialNB(alpha=bestAlpha)
nb.fit(X_train_scaled, y_train_new)

"""#**Predicciones y Metricas**"""

y_predict = nb.predict(X_test_scaled)

pd.crosstab(y_test_new, y_predict)

print(classification_report(y_test_new, y_predict));

"""# **Interpretacion**

En los valores predichos vs los datos de pruebas, el modelo obtuvo algunas equivocaciones en comparacion a los datos reales y que en donde mas podemos observar mas errores de prediccion fue en la variable "2", correspondiente a Standing de la variable Activities.

Sin embargo, el modelo NB obtuvo un valor de 0.86 en precision, lo que nos indica que el modelo funciona bien de todas formas y que es capaz de predicir datos con un 86% de precision con el set de pruebas del conjunto de datos. En conclusion, la capacidad predictiva del modelo para el conjunto de datos es bastante buena.
"""