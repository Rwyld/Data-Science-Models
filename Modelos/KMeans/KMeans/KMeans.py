# -*- coding: utf-8 -*-
"""M6 Ejercicio2 ErickSandoval.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MWRBYoYAjfU3-16xXjZxx5BusCOmUl5q

Calsificación de Clientes según su personalidad. 

---
En la base de datos _analisis.csv_ encontrará datos de famosos obtenidos midiendo su actividad en la red social Twitter. La idea es determinar, en base a los atributos, qué famosos son semejantes entre sí y qué famosos son distintos, también resulta interesante comprender cuántos tipos de perfiles se encontrará según la actividad en Twitter. 

Los atributos son los siguientes:

- usuario: Nombre en Twitter
- op: Openness to experience (grado de apertura mental a nuevas experiencias, curiosidad)
- co: Conscientiousness (grado de orden, prolijidad, organización)
- ex: Extraversion (grado de timidez ante el grupo social)
- ag: Agreeableness (grado de empatía con los demás)
- ne: Neuroticism (grado de neuroticismo, irritabilidad)
- Wordcount: Cantidad promedio de palabras usadas en sus tweets
- Categoria: Actividad laboral del usuario, dentro de los siguientes:
  1. Actor/actriz
  2. Cantante
  3. Modelo
  4. Tv, series
  5. Radio
  6. Tecnología
  7. Deportes
  8. Politica
  9. Escritor

# **Setup**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import make_blobs
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from sklearn.preprocessing import StandardScaler

data = pd.read_csv('https://raw.githubusercontent.com/Rwyld/Data-Science-Models/main/Modelos/KMeans/AnalisisCSV%20-%20KMeans.csv')
data.head()

#Dejando como índice la variable usuario 
newData = data.set_index('usuario')
newData.head(3)

"""# **Analisis Exploratorio**"""

data.info()

data.describe()

graphData = data.drop('usuario', axis = 1)

fig, axes = plt.subplots(nrows=7, ncols=1, figsize=(5,10))
axes = axes.flat
data = graphData.select_dtypes(include=['float64', 'int']).columns

for i, colum in enumerate(graphData):
    sns.histplot(
        data    = graphData,
        x       = colum,
        stat    = "count",
        kde     = True,
        color   = (list(plt.rcParams['axes.prop_cycle'])*2)[i]["color"],
        line_kws= {'linewidth': 2},
        alpha   = 0.3,
        ax      = axes[i]
    )
    axes[i].set_title(colum, fontsize = 8, fontweight = "bold")
    axes[i].tick_params(labelsize = 6)
    axes[i].set_xlabel("")

fig.tight_layout()
plt.subplots_adjust(top = .95)
fig.suptitle('Distribución variables numéricas', fontsize = 10, fontweight = "bold");

"""# **Relacion entre OP, EX y AG**"""

df2 = newData[['op', 'ex', 'ag']]

matrix = df2.corr()

print(matrix)

corrCategorias = newData.groupby('categoria')[['op', 'ex', 'ag']].mean()

print(corrCategorias)

corrCategorias.plot(kind='bar')

plt.xlabel('Categoria')
plt.ylabel('Mean')
plt.title('Correlacion con Categorias y variables OP, EX y AG')

plt.show()

"""# **Modelando K-Means**"""

modelData = graphData

kmeans = KMeans(
    init="random",
    n_clusters=9,
    n_init=10,
    max_iter=300,
    random_state=1234
)

kmeans.fit(modelData)

kmeans.labels_

clusterData = pd.DataFrame(modelData)
clusterData['cluster'] = kmeans.labels_
clusterData[clusterData['cluster'] == 1].head()

# El valor más bajo de SSE
print("El valor más bajo de SSE: ",kmeans.inertia_)
print("")
# Ubicaciones finales del centroide
print("Ubicaciones finales del centroide",kmeans.cluster_centers_)
print("")
# El número de iteraciones necesarias para converger
print("El número de iteraciones necesarias para converger",kmeans.n_iter_)

"""# **Determinando el mejor K**



"""

kmeans_kwargs = {
    "init": "random",
    "n_init": 10,
    "max_iter": 300,
    "random_state": 1234,
}

# Una lista contiene los valores de SSE para cada k
sse = []
for k in range(1, 10):
    kmeans = KMeans(n_clusters=k, **kmeans_kwargs)
    kmeans.fit(modelData)
    sse.append(kmeans.inertia_)

plt.style.use("fivethirtyeight")
 plt.plot(range(1, 10), sse)
 plt.xticks(range(1, 10))
 plt.xlabel("Number of Clusters")
 plt.ylabel("SSE")
 plt.show()

# Una lista contiene los coeficientes de silueta para cada k
silhouette_coefficients = []

# Empezamos con 2 grupos para el coeficiente de silueta
for k in range(2, 11):
    kmeans = KMeans(n_clusters=k, **kmeans_kwargs)
    kmeans.fit(modelData)
    score = silhouette_score(modelData, kmeans.labels_)
    silhouette_coefficients.append(score)

plt.style.use("fivethirtyeight")
plt.plot(range(2, 11), silhouette_coefficients)
plt.xticks(range(2, 11))
plt.xlabel("Numero de Clusters")
plt.ylabel("Coeficiente de Silueta")
plt.show()

"""# **Visualizacion con el mejor K**"""

modelData = graphData

kmeans = KMeans(
    init="random",
    n_clusters=3,
    n_init=10,
    max_iter=300,
    random_state=1234
)

kmeans.fit(modelData)

sns.scatterplot(x=modelData.op, y=modelData.wordcount, hue=kmeans.labels_);

sns.scatterplot(x=modelData.categoria, y=modelData.wordcount, hue=kmeans.labels_);
plt.legend(loc='upper right')

# El valor más bajo de SSE
print("El valor más bajo de SSE: ",kmeans.inertia_)
print("")
# Ubicaciones finales del centroide
print("Ubicaciones finales del centroide",kmeans.cluster_centers_)
print("")
# El número de iteraciones necesarias para converger
print("El número de iteraciones necesarias para converger",kmeans.n_iter_)

"""# **Visualizando por Actividades en el Cluster**"""

newClusterData = pd.DataFrame(modelData)
newClusterData['cluster'] = kmeans.labels_


result = pd.DataFrame(newClusterData)

result = result.groupby('cluster')['categoria'].count()
display(result)
result.plot(kind='bar')

cluster1 = newClusterData[newClusterData.cluster == 0]
resultCluster1 = cluster1.groupby('categoria')['categoria'].count()
ax = resultCluster1.plot(kind='bar')

cluster2 = newClusterData[newClusterData.cluster == 1]
resultCluster2 = cluster2.groupby('categoria')['categoria'].count()
ax = resultCluster2.plot(kind='bar')

cluster3 = newClusterData[newClusterData.cluster == 2]
resultCluster3 = cluster3.groupby('categoria')['categoria'].count()
ax = resultCluster3.plot(kind='bar')

"""# **Interpretando**

En conclusion, en el modelo de KMeans, la cantidad de clusters optimos segun el analisis de codo y de silueta, es de un valor K de 3.

Luego, al observar cada cluster por separados:

- 67 personas con personalidad similar en el primer cluster, donde se destacan las profesiones de Actor(1) y Cantante(2).
- 45 personas con personalidad similar en el segundo cluster, donde se destacan las profesiones TV(4), Deportes(7) y Cantante(2).
- 28 personas con personalidad similar en el ultimo cluster, donde se destacan las profesiones Actor(1) y Politica(8).
"""